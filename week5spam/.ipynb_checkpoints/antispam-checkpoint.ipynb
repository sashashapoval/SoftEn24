{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Installation\n",
    "\n",
    "* Read <a href = \"http://ix.cs.uoregon.edu/~conery/eic/python/installation.html\">here</a> if Python is in your Path\n",
    "* In the case of Anaconda, whichs add the required variables into the pass upon run, \n",
    "    * copy archive from the above site and unpack\n",
    "    * open Anacodna (power) shell, which adopts the Path, and run http://ix.cs.uoregon.edu/~conery/eic/python/installation.html\n",
    "    * if it fails, launch jupyter notebook, open the terminal and conduct the above command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'SpamLab' has no attribute 'Canvas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSpamLab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'SpamLab' has no attribute 'Canvas'"
     ]
    }
   ],
   "source": [
    "from PythonLabs.SpamLab import *\n",
    "#from wf import tokenize\n",
    "#from spamicity import spamicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Strings, their length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "s = 'I \\u2665 cats'\n",
    "print(s)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Counting Words in a Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a monthly message to inform you about the visibility of your works through RePEc. This message also contains information on how to update your profile.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "If you need to link to some research from a website or on social media, we want to encourage you to link to a RePEc page instead of directly to the full text. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fname = 'email1.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['This', 'is', 'a', 'monthly', 'message', 'to', 'inform', 'you', 'about', 'the', 'visibility', 'of', 'your', 'works', 'through', 'RePEc.', 'This', 'message', 'also', 'contains', 'information', 'on', 'how', 'to', 'update', 'your', 'profile.']\n",
      "This\n",
      "is\n",
      "a\n",
      "monthly\n",
      "message\n",
      "to\n",
      "inform\n",
      "you\n",
      "about\n",
      "the\n",
      "visibility\n",
      "of\n",
      "your\n",
      "works\n",
      "through\n",
      "RePEc.\n",
      "This\n",
      "message\n",
      "also\n",
      "contains\n",
      "information\n",
      "on\n",
      "how\n",
      "to\n",
      "update\n",
      "your\n",
      "profile.\n",
      "<class 'list'>\n",
      "[]\n",
      "<class 'list'>\n",
      "[]\n",
      "<class 'list'>\n",
      "['If', 'you', 'need', 'to', 'link', 'to', 'some', 'research', 'from', 'a', 'website', 'or', 'on', 'social', 'media,', 'we', 'want', 'to', 'encourage', 'you', 'to', 'link', 'to', 'a', 'RePEc', 'page', 'instead', 'of', 'directly', 'to', 'the', 'full', 'text.']\n",
      "If\n",
      "you\n",
      "need\n",
      "to\n",
      "link\n",
      "to\n",
      "some\n",
      "research\n",
      "from\n",
      "a\n",
      "website\n",
      "or\n",
      "on\n",
      "social\n",
      "media,\n",
      "we\n",
      "want\n",
      "to\n",
      "encourage\n",
      "you\n",
      "to\n",
      "link\n",
      "to\n",
      "a\n",
      "RePEc\n",
      "page\n",
      "instead\n",
      "of\n",
      "directly\n",
      "to\n",
      "the\n",
      "full\n",
      "text.\n",
      "<class 'list'>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "fname = 'email1.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        print(type(words))\n",
    "        print(words)\n",
    "        for word in words:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 60 323\n"
     ]
    }
   ],
   "source": [
    "#counts the number of lines, words, and characters in the file\n",
    "fname = 'email1.txt'\n",
    "nlines = nwords = nchars = 0\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        nlines += 1\n",
    "        nwords += len(line.split())\n",
    "        nchars += len(line)\n",
    "print(nlines, nwords, nchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After the code is tested, it is written as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 60 323\n"
     ]
    }
   ],
   "source": [
    "#counts the number of lines, words, and characters in the file\n",
    "def wc(fname):\n",
    "    nlines = nwords = nchars = 0\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f:\n",
    "            nlines += 1\n",
    "            nwords += len(line.split())\n",
    "            nchars += len(line)\n",
    "    return nlines, nwords, nchars\n",
    "\n",
    "nlines, nwords, nchars = wc('email1.txt')\n",
    "print(nlines, nwords, nchars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tuples: to recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = wc('email1.txt')\n",
    "print(len(x))\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Try to assign something to tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x[0] = 'Hurrah!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word frequency\n",
    "\n",
    "This is the modification of the code `wc()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The plan for the word frequency function is to use a dictionary that associates strings with\n",
    "integers, where the strings are words found in the input file and the integers are the number\n",
    "of times a word has been seen. We’ll call this dictionary `count`, and we will initialize it as an empty dictionary:\n",
    "\n",
    "`count = {}`\n",
    "\n",
    "If `x` is a word then `count[x]` is its count.\n",
    "\n",
    "When the word appears for the first time in the file its count has to be initialized\n",
    "\n",
    "A call of the form `setdefault(x,y)` means \"check to see if the item x is in the dictionary, and if not, insert it and give it the value y.\" \n",
    "\n",
    "If the item already is in the dictionary the method doesn’t do anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem:\n",
    "* distinguish `university` and `university,`\n",
    "`university` and `University`\n",
    "\n",
    "`s.strip('.1')` returns the string obtained from `s` by removing symbols '.' and '1' from the ends of the string (if any) so that we use\n",
    "\n",
    "`w.strip(punctuation).lower()`\n",
    "\n",
    "to obtain the universal form of the word `w`. The string with punctuation symbols is defined in the library. Use\n",
    "\n",
    "`from string import punctuation`\n",
    "\n",
    "* Details regarding `strip()` method are <a href = \"https://www.tutorialspoint.com/python/string_strip.htm\">here</a>\n",
    "\n",
    "Function `tokenize(s)` \n",
    "* takes a string\n",
    "* splits it into words\n",
    "* strips the punctuations\n",
    "* makes the words lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def tokenize(s):\n",
    "    \"Return the list of words in string s\"\n",
    "    #a = [x.strip(punctuation).lower() for x in s.split()]\n",
    "    \n",
    "    #a longer alternative\n",
    "    a = [ ]\n",
    "    for x in s.split():\n",
    "        a.append( x.strip(punctuation).lower() )\n",
    "    return a\n",
    "\n",
    "def wf(fn):\n",
    "    \"Make a dictionary of word frequencies\"\n",
    "    count = { }\n",
    "    for line in open(fn):\n",
    "        for w in tokenize(line):\n",
    "            count.setdefault(w, 0)\n",
    "            count[w] += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestion:\n",
    "\n",
    "* inspect the method `setdefault()`; for example, <a href = \"https://www.w3schools.com/python/ref_dictionary_setdefault.asp\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> __Note__: the punctuation string is a naive way to avoid the repetitions of the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bayesian indetification of the spam emails\n",
    "\n",
    "## Training\n",
    "\n",
    "* User classifies the emails as span / non-spam (this part of the job is pre-defined for us, but everybody can write the appropriate code)\n",
    "* The code computes the frequency of words in the emails of both types\n",
    "\n",
    "__Example__\n",
    "\n",
    "Word secret occurs $252$ times in $1000$ spam emails and $31$ times in $600$ good emails. Then the corresponding frequencies are $0.252$ and $31/600 = 0.052$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional probability\n",
    "\n",
    "### Example\n",
    "\n",
    "* We computed $P\\{$occurrence of word `secret` given that the email is bad$\\}$.\n",
    "* In more mathematical notation, it is\n",
    "$P\\{w | \\textrm{bad}\\}$,\n",
    "where $w$ stands for the word.\n",
    "\n",
    "### General description\n",
    "The conditional probability differes from the unconditional probability by the set of available outcomes.\n",
    "\n",
    "__Example__\n",
    "* If you throw a single dice, then it can fall six ways, each of which is equally likely if the dice is true. So the probability of getting one particular value is $1/6$. If you want either of two values it is $2/6$ or $1/3$, and so on. This is an example of undconditional probability\n",
    "* What is the probability that you face $6$ if the appeared number is even? In this case the probability is conditional. It is given that the the number is even so that there are only _three_ possible outcomes: $2$, $4$, and $6$. The probability of six is $1/3$. Notation: $P\\{X = 6 | X \\mathrm{\\ is\\ even}\\}$, where $X$ stands for the number of the die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u></span><br>\n",
    "    <li>Two coins are flipped. What is the probability of two heads if you that at least one heads is faced up?</summary>\n",
    "  \n",
    "  * There are $3$ outcomes: $HT$, $TH$, and $HH$, and the last one satisfies the task. The answer is $1/3$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u></span><br>\n",
    "    <li>Find the probability that the sum of two rolling dice is larger the $9$, given that it is even.</summary>\n",
    "  \n",
    "  * \"good\" outcomes are $(5,5)$, $(4,6)$, $(6,4)$, and $(6,6)$ among eighteen outcomes in total; $P = 4/18 = 2/9$.\n",
    "  * Why did we rule out the outcomes $(5,6)$ and $(6,5)$?\n",
    "  * Why there are $18$ outcomes in total?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u></span><br>\n",
    "    <li>Find the probability that the maximum number on three rolling dice is five, given that all numbers are equal.</summary>\n",
    "  \n",
    "  <li> $1/6$ </li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u></span><br>\n",
    "    <li>Two kids are in the family. One of them is a boy. What is the probability that the other is a boy?</summary>\n",
    "  \n",
    "  * Do it yourself\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P (A | B)  < = >   P(A)\n",
    "\n",
    "\n",
    "__Example 1__\n",
    "\n",
    "<br>\n",
    "Two coins\n",
    "<br>\n",
    "HH, HT, TH, TT\n",
    "\n",
    "A = HH\n",
    "<br>\n",
    "B = {HH, HT, TH}\n",
    "\n",
    "P(A | B) = 1/3\n",
    "<br>\n",
    "P(A) = 1/4\n",
    "\n",
    "In this example, $P (A | B)  >  P(A)$\n",
    "\n",
    "__Example 2__\n",
    "<br>\n",
    "The same coins\n",
    "A = HH,\n",
    "<br>\n",
    "B = TT\n",
    "P(A | B) = 0\n",
    "<br>\n",
    "P(A) = 1/4\n",
    "\n",
    "In this example, $P (A | B)  <  P(A)$\n",
    "\n",
    "__Example 3__\n",
    "<br>\n",
    "The same coins\n",
    "A = {HT, TH}\n",
    "<br>\n",
    "B = H* = {HH, HT}\n",
    "<br>\n",
    "P(A | B) = 1/2 (Because we waiting for the Tails after Heads)\n",
    "<br>\n",
    "P(A) = 2/4 = 1/2\n",
    "\n",
    "In this example, $P (A | B)  =  P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayes' rule\n",
    "\n",
    "$$\n",
    "  \\mathbb{P}\\{A|B\\} = \\frac{ \\mathbb{P}\\{B|A\\} \\mathbb{P}\\{A\\} }{ \\mathbb{P}\\{B\\} },\n",
    "$$\n",
    "where\n",
    "* $\\mathbb{P}\\{A|B\\}$ is the probability of event $A$ occurring, given event $B$ has occurred\n",
    "* $\\mathbb{P}\\{B|A\\}$ is the probability of event $B$ occurring, given event $A$ has occurred\n",
    "* $\\mathbb{P}\\{A\\}$ is the probability of event $A$\n",
    "* $\\mathbb{P}\\{B\\}$ is the probability of event $B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__More general version__\n",
    "* all outcomes are split into $n$ parts: $H_1$, $H_2$, $\\ldots$, $H_n$. In other words, each possible outcome of the experiment belongs to one (and only one) sets among $H_1$, $H_2$, $\\ldots$, $H_n$.\n",
    "* Then\n",
    "$$\n",
    "  \\mathbb{P}\\{H_1|X\\} = \\frac{ \\mathbb{P}\\{X|H_1\\} \\mathbb{P}\\{H_1\\} }{ \\mathbb{P}\\{X\\} }\n",
    "$$\n",
    "or\n",
    "$$\n",
    "  \\mathbb{P}\\{H_1|X\\} = \\frac{ \\mathbb{P}\\{X|H_1\\} \\mathbb{P}\\{H_1\\} }{ \\sum_{i=1}^n \\mathbb{P}\\{X|H_i\\} \\mathbb{P}\\{H_i\\} }\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span> What can you say about the probability $\\mathbb{P}\\{H_2|X\\}$</summary>\n",
    "  \n",
    "  $$\n",
    "  \\mathbb{P}\\{H_j|X\\} = \n",
    "  \\frac{ \\mathbb{P}\\{X|H_j\\} \\mathbb{P}\\{H_j\\} }{ \\mathbb{P}\\{X\\} } = \n",
    "  \\frac{ \\mathbb{P}\\{X|H_j\\} \\mathbb{P}\\{H_j\\} }{ \\sum_{i=1}^n \\mathbb{P}\\{X|H_i\\} \\mathbb{P}\\{H_i\\} }\n",
    "  $$\n",
    "  for any $j = 1, \\ldots, n$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Additional example\n",
    "\n",
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span><li>You know that a coin is two-headed with probability of $1/1000$. A coin taken in random shows up heads $10$ times in a row. What is the probability that it is with heads on the both sides?</summary>\n",
    "  \n",
    "  <li> Settings: $H_1$ indicates that the coin is normal </li>\n",
    "  <li> $H_2$ indicates that the coin is with two heads </li>\n",
    "  <li> Then $H_1 + H_2 = 1$ </li>\n",
    "  <li> $X$ means that flipping a coin $10$ times you observe $10$ heads\n",
    "  <li> Bayes' rule:\n",
    "  $$ \\mathbb{P}\\{H_2|X\\} = \n",
    "  \\frac{ \\mathbb{P}\\{X|H_2\\} \\mathbb{P}\\{H_2\\} }{ \\mathbb{P}\\{X|H_1\\} \\mathbb{P}\\{H_1\\} + \\mathbb{P}\\{X|H_2\\} \\mathbb{P}\\{H_2\\} } =\n",
    "  \\frac{ 1 \\cdot 0.001 }{ 1 \\cdot 0.001 + 0.5^{10} \\cdot 0.999 } \\approx 0.50$$ </li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5061789421651013"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.001 / ( 0.001 + 0.5**10 * 0.999 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Relation to practical questions\n",
    "\n",
    "We are interested in characteristics (does the email belong to spam?) based on some data (the set of emails). The answer can be done in a probabilistic form: the probability that the characteristics belongs to a class based on the data. This is the conditional probability we've just discussed. If the belongness to the class is $\\theta^*$, we can write\n",
    "\n",
    "$$\n",
    "  \\mathbb{P}\\{\\theta^* | \\mathrm{data}\\} = \n",
    "  \\frac{ \\mathbb{P}\\{\\mathrm{data} | \\theta^*\\}\\mathbb{P}\\{\\theta^*\\} }\n",
    "  { \\sum_{\\theta} \\mathbb{P}\\{\\mathrm{data} | \\theta\\}\\mathbb{P}\\{\\theta\\} }\n",
    "$$\n",
    "$\\mathbb{P}\\{\\theta^* | \\mathrm{data}\\}$ is called the _aposteriori_ probability. The computation is based on _apriori_ probabilities $\\mathbb{P}\\{\\theta\\}$ and the likelihood funtion $\\mathbb{P}\\{\\mathrm{data} | \\theta\\}$.\n",
    "\n",
    "The likelihood function is estimated with the data. The choice of the _apriori_ probabilities is questionable.\n",
    "\n",
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><li><u>Question</u> What quantitites from the above equations are easier to esimate? More complicated?</li><li>How can they be estimated?</li></span><br>\n",
    "    </summary>\n",
    "  \n",
    "  <li> The probabilities $\\mathbb{P}\\{\\mathrm{data} | \\theta^*\\}$ are derived estimated from the data (the training stage) </li>\n",
    "  <li> The _apriori_ probabilities $\\mathbb{P}\\{\\theta\\}$ are always difficult to estimate. The exact choice of the _apriori_ probabilities is not so important if there are grounds to believe that the update process with the Bayes' rule converges </li>\n",
    "</details>       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Application to the detection of spam\n",
    "\n",
    "We plan to find the probability $\\mathbb{P}\\{ \\mathrm{spam} | w \\}$, which is the probability that the message is spam given that we see some word $w$ in the message. According to the Bayes' rule,\n",
    "$$\n",
    "  \\mathbb{P}\\{ \\mathrm{spam} | w \\} = \n",
    "  \\frac{ \\mathbb{P}\\{ w | \\mathrm{spam} | \\}\\mathbb{P}\\{\\mathrm{spam}\\} }\n",
    "  { \\mathbb{P}\\{ w | \\mathrm{spam} | \\} \\mathbb{P}\\{\\mathrm{spam}\\} +\n",
    "  \\mathbb{P}\\{ w | \\mathrm{good} | \\} \\mathbb{P}\\{\\mathrm{good}\\} }\n",
    "$$\n",
    "* The probabilities $\\mathbb{P}\\{ w | \\mathrm{good} | \\}$\n",
    "and $\\mathbb{P}\\{ w | \\mathrm{spam} | \\}$ are estimated during the training.\n",
    "* Apriori probabilities $\\mathbb{P}\\{\\mathrm{spam}\\}$ and $\\mathbb{P}\\{\\mathrm{good}\\}$ are not known\n",
    "* The simplest way is to assign $0.5$ to these unknown probabilities.\n",
    "* Let us denote $\\mathrm{spamcity}(w)$ the corresponding estimates of $\\mathbb{P}\\{ \\mathrm{spam} | w \\}$. Eventually,\n",
    "$$\n",
    "  \\mathrm{spamcity}(w) = \n",
    "  \\frac{ \\mathbb{P}\\{ w | \\mathrm{spam} | \\} }\n",
    "  { \\mathbb{P}\\{ w | \\mathrm{spam} | \\}  +\n",
    "  \\mathbb{P}\\{ w | \\mathrm{good} | \\} }.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span><li>If $\\mathrm{spamcity}(w)$ is close to $1$, the word $w$ appears in spam messages more frequently than in non-span messages. Is it correct?</summary>\n",
    "  \n",
    "  <li> Yes</li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span><li>Try other _apriori_ probabilities</li></summary>\n",
    "  \n",
    "  <li> Do it yourself</li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def spamcity(w, pbad, pgood):\n",
    "    #Compute the probability a messaage is spam when it contains a word w.\\\n",
    "    #The dictionaries pbad and pgood hold p(w|spam) and p(w|good), respectively.\n",
    "    if w in pbad and w in pgood:\n",
    "        return pbad[w] / ( pbad[w] + pgood[w] )\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### New words\n",
    "\n",
    "An important detail we haven’t considered yet is what to do if a word in an incoming message was never seen during training. This is clearly something we have to anticipate. New words continually being added to the English language, and spammers like to try to\n",
    "disguise words, e.g. writing \"m0ney\" instead of \"money.\"\n",
    "To address this problem, the spamicity function first needs to make sure\n",
    "the word is defined in both dictionaries. The `if` statement on line 4 tests to see if the word is in both dictionaries, and if so the spamicity equation is used to compute the value returned by the function. If the word is missing from one (or both) of the dictionaries the special object `None` is returned as a signal that spamicity is not defined for this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "__Usage of the probabilities predefined by our predecessors__\n",
    "\n",
    "A function named `load_probabilities` will read the data from one of the training sets and return it in a dictionary object that associates a word with its probability. The two files are named `good.txt` and `bad.txt`, so to create the two dictionaries we just find the paths\n",
    "to the files and pass them to load_probabilities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.127\n",
      "0.0164\n",
      "0.8856345885634589\n"
     ]
    }
   ],
   "source": [
    "#pgood = load_probabilities(path_to_data('good.txt')) #author version\n",
    "#pbad = load_probabilities(path_to_data('bad.txt')) #author version\n",
    "#you can use the direct path to data instead\n",
    "pgood = load_probabilities('good.txt') #author version\n",
    "pbad = load_probabilities('bad.txt') #author version\n",
    "print(pbad['money'])\n",
    "print(pgood['money'])\n",
    "print(spamcity('money', pbad, pgood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code of __load_probabilities()__\n",
    "\n",
    "### First, code and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 0.0009 fawn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fawn': 0.0009}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = { }\n",
    "with open('good.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        p, w = line.split()\n",
    "        prob.update({w: (float(p))})\n",
    "        #prob[w] = float(p) #another way  to update the dictionary\n",
    "        break; # just to test the first line\n",
    "print(type(prob), p, w)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, write it as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_probabilities(fn):\n",
    "    prob = { }\n",
    "    with open(fn, 'r') as f:\n",
    "        for line in f:\n",
    "            p, w = line.split()\n",
    "            prob.update({w: (float(p))})\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003\n"
     ]
    }
   ],
   "source": [
    "dict = load_probabilities('good.txt')\n",
    "print(dict['marching'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span><li>Describe <span style = \"background-color:#E5E4E2;\">prob</span> returned by the function <span style = \"background-color:#E5E4E2;\">load_probabilities()</span></li></summary>\n",
    "  \n",
    "  <li> <span style = \"background-color:#E5E4E2;\">prob</span> is a dictionary </li>\n",
    "  <li> its keys are the words </li>\n",
    "  <li> its values are the probabilities, technically the values from the first column of the file </li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span><li>Why did not we verify that the words are distinct when forming the dictionary?</li></summary>\n",
    "  \n",
    "   <li> It is assumed that this job is performed earlier, when files __good.txt__ and __bad.txt__ are created. </li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Algorithm for Identifying Junk Mail\n",
    "\n",
    "The spamicity function tells us something about a single word, but classifying an entire\n",
    "message as spam just because it has one highly spammy word is not going to be very reliable.\n",
    "A typical message will have dozens of words, some that will predict the message is spam, and others pointing in the opposite direction. What we need is a method for combining\n",
    "probabilities of individual words into a single overall probability for the entire message.\n",
    "\n",
    "One approach, introduced by computer scientist Paul Graham is to consider only the\n",
    "most “interesting” words. The idea is to use words that have either very high or very low\n",
    "spamicity, since those are the ones that give us the most information about the message. A word with a spamicity of $0.5$ is not very informative since it appears equally often in spam\n",
    "and good messages. Words farther away from $0.5$, either closer to $0$ or closer to $1$, will tell us more about the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Combined probability of spam\n",
    "\n",
    "* Let $p_i$ be the probability that the message with word `w_i` is spam. You could also write that $p_i = \\mathrm{spamcity}(w_i)$\n",
    "* Let $q_i = 1 - p_i$\n",
    "* Then processing a message, we deal with the set of words and the set of corresponding probabilities $p_1$, $\\ldots$, $p_n$, where $n$ is large\n",
    "* If the underlying events were independent we would write that the probability that the message belongs to spam is the product of the probabilities related to the individual words.\n",
    "* The equation is\n",
    "$$\n",
    "  \\mathrm{Probability}\\{\\mathrm{spam}\\} = \n",
    "  \\frac{p_1 \\cdot \\ldots \\cdot p_n}\n",
    "  { p_1 \\cdot \\ldots \\cdot p_n + q_1 \\cdot \\ldots \\cdot q_n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "  <summary><span style = \"font-weight:bold; color:blue;\"><u><li>Task:</u> </span><li>Your decision is based on the words with the spamcities \n",
    "$p_1 = 0.99$, $p_2 = 0.15$, $p_3 = 0.10$. What is the probability of the fact that the message is spam?</li></summary>\n",
    "  \n",
    "  <li> $$P = \\frac{0.99 \\cdot 0.15 \\cdot 0.10}{0.99 \\cdot 0.15 \\cdot 0.10 + (1 - 0.99) \\cdot (1 - 0.15) \\cdot (1 - 0.10)}$$ </li>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6599999999999998"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.99 * 0.15 * 0.10 / ( 0.99 * 0.15 * 0.10 + (1-0.99) * (1-0.15) * (1-0.10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Class `Queue` is defined in `SpamLab` library. It contains words and word.p() returns the (estimated) probability that the message with word `word` belongs to spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "def combined_probability(queue):\n",
    "    p = q = 1.0\n",
    "    for x in queue.probs():\n",
    "        p *= x\n",
    "        q *= (1.0 - x)\n",
    "    return p / (p + q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reduction of the words to use\n",
    "\n",
    "If we know the spamicity of a word we can define the “interestingness quotient” (IQ) of the word using this formula:\n",
    "$$\n",
    "  \\mathrm{IQ} = | 0.5 − s |\n",
    "$$\n",
    "Boring words, with a spamicity around\n",
    "$0.5$, will have an IQ close to $0$. But words with a very high spamicity near $1.0$, or a very low spamicity close to $0$, will lead to higher IQ values.\n",
    "In order to find the interesting words in a message we can store the words in a special\n",
    "type of list known as a priority queue. Structurally, a priority queue is just like a list: it’s a\n",
    "linear container with references to other objects. What distinguishes a priority queue from\n",
    "a regular list is that the objects in the priority queue are always sorted. Each time we add\n",
    "a new item to a priority queue, the item is automatically saved in a location that preserves\n",
    "the order. In our spam filtering program we will store words according to how interesting\n",
    "they are, so that words with a high IQ value will always be toward the front of the list.\n",
    "\n",
    "The `SpamLab` module has a class named WordQueue that implements this behavior. The\n",
    "size of the queue is specified when the WordQueue object is created. For example, if we want\n",
    "to keep track of the 10 most interesting words in a message we should create a `WordQueue` with room for $10$ words:\n",
    "\n",
    "`pq = WordQueue(10)`\n",
    "\n",
    "To display the new `WordQueue` object pass it to a function named `view_queue`:\n",
    "\n",
    "`view_queue(pq)`\n",
    "\n",
    "But first some words have to be added into the queue by the method `insert`:\n",
    "\n",
    "`pq.insert(word, probability)`\n",
    "\n",
    "For example,\n",
    "\n",
    "`pq.insert('money', 0.8)`\n",
    "\n",
    "or\n",
    "\n",
    "`pq.insert('money', spamcity('money', pbad, pgood))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('money', 0.8856345885634589, 0.3856345885634589)]\n"
     ]
    }
   ],
   "source": [
    "pq = WordQueue(10)\n",
    "pq.insert('money', spamcity('money', pbad, pgood))\n",
    "# I cannot get the predicted output with Jupyther notebook\n",
    "# Therefore I simply expose the queue with print()\n",
    "print(pq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define the function that aggregates the above reasoning and output the desired probability that the message is spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%run SpamLab.py\n",
    "def pspam(fn):\n",
    "    \"Compute the probability the message in file fn is spam\"\n",
    "    queue = WordQueue(15)\n",
    "    pgood = load_probabilities('good.txt')\n",
    "    pbad = load_probabilities('bad.txt')\n",
    "    for line in open(fn):\n",
    "        for word in tokenize(line):\n",
    "            p = spamicity(word, pbad, pgood)\n",
    "            if p != None:\n",
    "                queue.insert(word, p)\n",
    "    return combined_probability(queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimized version of the predefined code\n",
    "\n",
    "1. If you cannot install library __PythonLabs.SpamLab__ as was strongly recommended you can use the following:\n",
    "2. Modified version of the original __SpamLab.py__ that additionally contains the definition of class `PQBase` taken from the original file __Tools.py__\n",
    "3. Run the cells with the definitions of the functions\n",
    "  * `tokenize()`\n",
    "  * `wf()`\n",
    "  * `spamcity()`\n",
    "  * `load_probabilities()`\n",
    "  * `combined_probability()`\n",
    "  * `pspam()`\n",
    "4. Add the line\n",
    "````python\n",
    "%run SpamLab.py\n",
    "````\n",
    "in the first line of the cell with the function `pspam()`\n",
    "5. The instruction is prepared for _Jupyter notebook_. Only the last item is related to the chosen IDE. Think of adding the definitions from __SpamLab.py__ for other IDEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a monthly message to inform you about the visibility of your works through RePEc. This message also contains information on how to update your profile.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "If you need to link to some research from a website or on social media, we want to encourage you to link to a RePEc page instead of directly to the full text. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fn = 'email1.txt'\n",
    "with open(fn, 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1670071921857966e-08\n"
     ]
    }
   ],
   "source": [
    "fn = 'email1.txt'\n",
    "print(pspam(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9293048326577117\n"
     ]
    }
   ],
   "source": [
    "print(pspam('msg1.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "we discussed\n",
    "\n",
    "* simple operations with string\n",
    "* basic of tuples\n",
    "* Bayes' rule\n",
    "* Application of _aposteriori_ estimates, which is the core of the Bayesian approach in machine learning\n",
    "* Simple design of the spam filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Typical questions\n",
    "\n",
    "* Regarding python: operations with strings and tuples\n",
    "* Mathematics: Bayes' rule and its application to the estimates of _aposteori_ probabilities\n",
    "* Tests of the spam filter\n",
    "* Ideas of improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
